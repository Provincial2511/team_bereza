{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": "# team_bereza — Test Notebook\n\nПоследовательные тесты всех модулей RAG-пайплайна.  \nКаждая секция независима — можно запускать по отдельности.\n\n| Секция | Что тестируем | Нужен GPU? |\n|--------|--------------|------------|\n| 0 | Окружение, CUDA, зависимости | — |\n| 1 | Config | — |\n| 2 | OCR (EasyOCR + PyMuPDF) | желательно |\n| 3 | Parser (семантический чанкер) | — |\n| 4 | TextEmbedder | — |\n| 5 | FaissStore | — |\n| 6 | LocalGenerator | **да** |\n| 7 | Полный пайплайн | **да** |\n| 8 | Валидация ответа | — |"
  },
  {
   "cell_type": "markdown",
   "id": "cell-env-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Окружение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python : {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA   : {torch.version.cuda}\")\n",
    "print(f\"GPU    : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  Device : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  VRAM   : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Выбор устройства для всего ноутбука\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nDevice : {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем, что все зависимости установлены\n",
    "import importlib\n",
    "\n",
    "deps = [\n",
    "    \"fitz\",           # PyMuPDF\n",
    "    \"easyocr\",\n",
    "    \"faiss\",\n",
    "    \"sentence_transformers\",\n",
    "    \"transformers\",\n",
    "    \"docx\",           # python-docx\n",
    "    \"numpy\",\n",
    "    \"PIL\",            # Pillow\n",
    "]\n",
    "\n",
    "for dep in deps:\n",
    "    try:\n",
    "        importlib.import_module(dep)\n",
    "        print(f\"  OK  {dep}\")\n",
    "    except ImportError:\n",
    "        print(f\"  MISSING  {dep}  <-- pip install\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-src-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем импорт всех модулей проекта\n",
    "from src.config import Config\n",
    "from src.ocr import extract_text_from_pdf\n",
    "from src.parser import GuidelineParserStub\n",
    "from src.embeddings import TextEmbedder\n",
    "from src.faiss_store import FaissStore\n",
    "from src.generator import LocalGenerator\n",
    "\n",
    "print(\"Все модули src/ импортированы успешно.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Config\n",
    "from dataclasses import asdict\n",
    "import json\n",
    "\n",
    "cfg = Config(device=DEVICE)\n",
    "print(json.dumps(asdict(cfg), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ocr-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. OCR — EasyOCR + PyMuPDF\n",
    "\n",
    "Тест включает:\n",
    "- детекцию нативного текстового слоя\n",
    "- извлечение текста (нативное или через EasyOCR)\n",
    "- проверку нормализации (сохранение абзацев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ocr-detect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from pathlib import Path\n",
    "\n",
    "PDF_PATH = cfg.guideline_pdf_path\n",
    "assert Path(PDF_PATH).is_file(), f\"PDF не найден: {PDF_PATH}\"\n",
    "\n",
    "# Проверяем наличие текстового слоя\n",
    "with fitz.open(PDF_PATH) as doc:\n",
    "    total_pages = len(doc)\n",
    "    pages_with_text = sum(1 for p in doc if p.get_text().strip())\n",
    "\n",
    "print(f\"Страниц всего : {total_pages}\")\n",
    "print(f\"Страниц с текстом: {pages_with_text}\")\n",
    "print(f\"Режим извлечения: {'native' if pages_with_text > 0 else 'OCR (EasyOCR)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ocr-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ocr import extract_text_from_pdf\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "guideline_text = extract_text_from_pdf(PDF_PATH, languages=[\"ru\"])\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "paragraphs = [p for p in guideline_text.split(\"\\n\\n\") if p.strip()]\n",
    "\n",
    "print(f\"Время         : {elapsed:.1f}s\")\n",
    "print(f\"Символов      : {len(guideline_text):,}\")\n",
    "print(f\"Абзацев (\\\\n\\\\n): {len(paragraphs)}\")\n",
    "print()\n",
    "print(\"=== Первые 3 абзаца ===\")\n",
    "for i, p in enumerate(paragraphs[:3]):\n",
    "    print(f\"[{i}] {p[:200]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-parser-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Parser — семантический чанкер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-parser-unit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Юнит-тест на синтетическом тексте\n",
    "from src.parser import GuidelineParserStub\n",
    "\n",
    "parser = GuidelineParserStub(chunk_size=30, overlap=5)\n",
    "\n",
    "sample = (\n",
    "    \"Первый абзац: краткие сведения о заболевании.\\n\\n\"\n",
    "    \"Второй абзац: диагностика и лабораторные показатели.\\n\\n\"\n",
    "    \"Третий абзац: принципы лечения первой линии.\\n\\n\"\n",
    "    \"Четвёртый абзац: реабилитация и наблюдение после терапии.\"\n",
    ")\n",
    "\n",
    "chunks = parser.parse(sample)\n",
    "print(f\"Входных абзацев: 4\")\n",
    "print(f\"Выходных чанков: {len(chunks)}\")\n",
    "print()\n",
    "for i, c in enumerate(chunks):\n",
    "    print(f\"[{i}] {c!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-parser-real",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест на реальном тексте из PDF\n",
    "# guideline_text должен быть получен в секции OCR выше\n",
    "import time\n",
    "\n",
    "parser_real = GuidelineParserStub(\n",
    "    chunk_size=cfg.chunk_size,\n",
    "    overlap=cfg.overlap,\n",
    "    model_name=cfg.embedder_model,\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "chunks = parser_real.parse(guideline_text)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "token_counts = [\n",
    "    len(parser_real.tokenizer.encode(c, add_special_tokens=False))\n",
    "    for c in chunks\n",
    "]\n",
    "\n",
    "print(f\"Время     : {elapsed:.2f}s\")\n",
    "print(f\"Чанков    : {len(chunks)}\")\n",
    "print(f\"Токенов   : min={min(token_counts)}, max={max(token_counts)}, avg={sum(token_counts)//len(token_counts)}\")\n",
    "print()\n",
    "print(\"=== Первые 2 чанка ===\")\n",
    "for i, c in enumerate(chunks[:2]):\n",
    "    print(f\"[{i}] ({token_counts[i]} tok) {c[:300]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-embed-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. TextEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-embed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings import TextEmbedder\n",
    "import numpy as np\n",
    "\n",
    "embedder = TextEmbedder(model_name=cfg.embedder_model)\n",
    "\n",
    "# embed_text\n",
    "single = embedder.embed_text(\"Рак лёгкого: диагностика и лечение\")\n",
    "print(f\"embed_text  shape : {single.shape}, dtype: {single.dtype}\")\n",
    "print(f\"L2 norm           : {np.linalg.norm(single):.6f}  (должно быть ~1.0)\")\n",
    "\n",
    "# embed_batch\n",
    "batch_texts = [\n",
    "    \"Хирургическое лечение немелкоклеточного рака лёгкого\",\n",
    "    \"Химиотерапия при мелкоклеточном раке\",\n",
    "    \"Иммунотерапия ингибиторами контрольных точек\",\n",
    "]\n",
    "batch = embedder.embed_batch(batch_texts)\n",
    "print(f\"\\nembed_batch shape : {batch.shape}\")\n",
    "norms = np.linalg.norm(batch, axis=1)\n",
    "print(f\"L2 norms          : {norms}  (все ~1.0)\")\n",
    "\n",
    "# Косинусное сходство между парами\n",
    "sims = batch @ batch.T\n",
    "print(f\"\\nКосинусная матрица сходства (normalized L2 = cosine):\")\n",
    "print(np.round(sims, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-faiss-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. FaissStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-faiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.faiss_store import FaissStore\n",
    "import tempfile, os\n",
    "\n",
    "# Создаём in-memory store с синтетическими данными\n",
    "texts = [\n",
    "    \"Хирургическое лечение немелкоклеточного рака лёгкого\",\n",
    "    \"Химиотерапия при мелкоклеточном раке\",\n",
    "    \"Иммунотерапия ингибиторами контрольных точек\",\n",
    "    \"Таргетная терапия при EGFR-мутации\",\n",
    "    \"Лучевая терапия при раке лёгкого\",\n",
    "]\n",
    "embeddings = embedder.embed_batch(texts)\n",
    "metadata = [{\"id\": i} for i in range(len(texts))]\n",
    "\n",
    "store = FaissStore(dimension=embeddings.shape[1])\n",
    "store.add(texts, embeddings, metadata)\n",
    "print(f\"Добавлено векторов: {store.index.ntotal}\")\n",
    "\n",
    "# Поиск\n",
    "query = \"Лечение EGFR мутация таргетная\"\n",
    "q_emb = embedder.embed_text(query)[0]\n",
    "results = store.search(q_emb, top_k=3)\n",
    "\n",
    "print(f\"\\nЗапрос: '{query}'\")\n",
    "print(\"Результаты:\")\n",
    "for r in results:\n",
    "    print(f\"  score={r['score']:.4f}  {r['text']}\")\n",
    "\n",
    "# Сохранение и загрузка\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    store.save(tmpdir)\n",
    "    files = os.listdir(tmpdir)\n",
    "    print(f\"\\nСохранённые файлы: {files}\")\n",
    "\n",
    "    store2 = FaissStore(dimension=embeddings.shape[1])\n",
    "    store2.load(tmpdir)\n",
    "    results2 = store2.search(q_emb, top_k=1)\n",
    "    print(f\"После load — top-1: {results2[0]['text']}\")\n",
    "\n",
    "print(\"\\nFaissStore: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-faiss-real-header",
   "metadata": {},
   "source": [
    "### 5.1 Загрузить существующий индекс с диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-faiss-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from pathlib import Path\n",
    "\n",
    "INDEX_DIR = cfg.faiss_index_path\n",
    "index_exists = all(\n",
    "    Path(INDEX_DIR, f).exists()\n",
    "    for f in [\"index.faiss\", \"texts.pkl\", \"metadata.pkl\"]\n",
    ")\n",
    "\n",
    "if index_exists:\n",
    "    temp = faiss.read_index(str(Path(INDEX_DIR) / \"index.faiss\"))\n",
    "    real_store = FaissStore(dimension=temp.d)\n",
    "    real_store.load(INDEX_DIR)\n",
    "    del temp\n",
    "\n",
    "    q_real = embedder.embed_text(\"EGFR мутация таргетная терапия первая линия\")[0]\n",
    "    results = real_store.search(q_real, top_k=3)\n",
    "\n",
    "    print(f\"Векторов в индексе: {real_store.index.ntotal}\")\n",
    "    print(f\"Dimension         : {real_store.dimension}\")\n",
    "    print()\n",
    "    print(\"Top-3 по запросу 'EGFR мутация таргетная терапия первая линия':\")\n",
    "    for r in results:\n",
    "        print(f\"  score={r['score']:.4f}  {r['text'][:150]}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Индекс не найден — запусти секцию 7 (полный пайплайн) для его создания.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-gen-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. LocalGenerator\n",
    "\n",
    "> **Требования**: Qwen2-7B-Instruct ~ 14 GB VRAM (GPU) / ~28 GB RAM (CPU).  \n",
    "> На CPU работает, но очень медленно. На A100 / H100 — несколько секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gen-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generator import LocalGenerator\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "generator = LocalGenerator(model_name=cfg.generator_model, device=DEVICE)\n",
    "print(f\"Модель загружена за {time.time() - t0:.1f}s\")\n",
    "print(f\"Device: {generator.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gen-prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем системные промпты\n",
    "for mode in (\"doctor\", \"patient\"):\n",
    "    prompt = generator._get_system_prompt(mode)\n",
    "    print(f\"[{mode}] первые 120 символов: {prompt[:120]!r}\")\n",
    "\n",
    "# Проверяем валидацию неизвестного режима\n",
    "try:\n",
    "    generator._get_system_prompt(\"unknown\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\nОжидаемая ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gen-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем apply_chat_template (без инференса)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Ты ассистент.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Привет!\"},\n",
    "]\n",
    "formatted = generator.tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(\"Chat template output:\")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gen-generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация на синтетических данных\n",
    "import time\n",
    "\n",
    "SYNTHETIC_SECTIONS = [\n",
    "    \"При EGFR-мутации (делеция 19 экзона или замена L858R) рекомендована таргетная терапия ингибиторами тирозинкиназы первого поколения.\",\n",
    "    \"Хирургическое лечение рекомендовано при I–II стадии НМРЛ при отсутствии противопоказаний.\",\n",
    "    \"Химиотерапия первой линии на основе препаратов платины рекомендована при отсутствии активирующих мутаций.\",\n",
    "]\n",
    "SYNTHETIC_PATIENT = (\n",
    "    \"Пациент 58 лет. Диагноз: аденокарцинома лёгкого, стадия IIIA. \"\n",
    "    \"EGFR мутация: делеция 19 экзона. Назначен гефитиниб.\"\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "response = generator.generate(\n",
    "    patient_text=SYNTHETIC_PATIENT,\n",
    "    retrieved_sections=SYNTHETIC_SECTIONS,\n",
    "    mode=\"doctor\",\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"Время генерации: {elapsed:.1f}s\")\n",
    "print(f\"Токенов в ответе: ~{len(response.split())}\")\n",
    "print()\n",
    "print(\"=== Ответ (режим doctor) ===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gen-patient-mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# То же самое в режиме patient\n",
    "t0 = time.time()\n",
    "response_patient = generator.generate(\n",
    "    patient_text=SYNTHETIC_PATIENT,\n",
    "    retrieved_sections=SYNTHETIC_SECTIONS,\n",
    "    mode=\"patient\",\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(f\"Время: {time.time() - t0:.1f}s\")\n",
    "print()\n",
    "print(\"=== Ответ (режим patient) ===\")\n",
    "print(response_patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pipeline-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Полный пайплайн (end-to-end)\n",
    "\n",
    "Запускает `main()` целиком.  \n",
    "Если FAISS-индекс уже есть — OCR и чанкинг пропускаются.  \n",
    "Чтобы пересобрать индекс — удали папку `data/faiss_index/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pipeline-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментировать, чтобы сбросить индекс и пересобрать с нуля\n",
    "# import shutil\n",
    "# shutil.rmtree(cfg.faiss_index_path, ignore_errors=True)\n",
    "# print(\"Индекс удалён.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pipeline-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск полного пайплайна через main()\n",
    "# Если выше уже загружен generator — можно переиспользовать, но main() создаёт его заново.\n",
    "import importlib\n",
    "import main as main_module\n",
    "importlib.reload(main_module)  # подхватываем изменения без перезапуска ядра\n",
    "\n",
    "main_module.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pipeline-inspect",
   "metadata": {},
   "source": [
    "### 7.1 Посмотреть сохранённые результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pipeline-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "response_dir = Path(cfg.response_dir)\n",
    "versions = sorted(response_dir.glob(\"version_*.json\"))\n",
    "\n",
    "if not versions:\n",
    "    print(\"Нет сохранённых результатов.\")\n",
    "else:\n",
    "    latest = versions[-1]\n",
    "    with latest.open(encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"Файл    : {latest.name}\")\n",
    "    print(f\"Версия  : {data['version']}\")\n",
    "    print(f\"Режим   : {data['mode']}\")\n",
    "    print(f\"Модель  : {data['model_name']}\")\n",
    "    print(f\"Старт   : {data['timestamp_start']}\")\n",
    "    print(f\"Конец   : {data['timestamp_end']}\")\n",
    "    print(f\"Итого   : {data['total_duration_seconds']}s\")\n",
    "    print()\n",
    "    print(\"Этапы:\")\n",
    "    for stage, dur in data['stage_durations'].items():\n",
    "        print(f\"  {stage:<20} {dur}s\")\n",
    "    print()\n",
    "    print(\"=== Финальный ответ ===\")\n",
    "    print(data['final_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4uv2hgmhgfq",
   "source": "---\n## 8. Валидация ответа\n\nАвтоматические проверки качества сгенерированного ответа.  \nЗапускать после секции 7 (либо загрузить любой `version_N.json` вручную).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "919mgz5ponn",
   "source": "### 8.1 Загрузка версии для анализа",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1p4fbsob2kg",
   "source": "import json\nfrom pathlib import Path\n\n# Поменяй номер версии при необходимости, None = последняя\nEVAL_VERSION = None\n\nresponse_dir = Path(cfg.response_dir)\nversions = sorted(response_dir.glob(\"version_*.json\"))\nassert versions, \"Нет сохранённых результатов — запусти секцию 7.\"\n\ntarget = versions[-1] if EVAL_VERSION is None else response_dir / f\"version_{EVAL_VERSION}.json\"\nassert target.exists(), f\"Файл не найден: {target}\"\n\nwith target.open(encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nresponse      = data[\"final_response\"]\nretrieved     = data.get(\"retrieved_sections\", [])\nmode          = data.get(\"mode\", \"—\")\nmodel_name    = data.get(\"model_name\", \"—\")\ntotal_dur     = data.get(\"total_duration_seconds\", 0)\nstage_dur     = data.get(\"stage_durations\", {})\n\nprint(f\"Версия  : {data['version']}\")\nprint(f\"Режим   : {mode}\")\nprint(f\"Модель  : {model_name}\")\nprint(f\"Длит.   : {total_dur}s\")\nprint(f\"Чанков  : {len(retrieved)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "q1obucp2zoh",
   "source": "### 8.2 Структурные проверки",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "68yla3crgpp",
   "source": "checks = []\n\ndef check(name, condition, detail=\"\"):\n    status = \"OK  \" if condition else \"FAIL\"\n    checks.append((status, name, detail))\n    print(f\"  [{status}]  {name}\" + (f\"  →  {detail}\" if detail else \"\"))\n\nprint(\"=== Структурные проверки ===\\n\")\n\n# 1. Дисклеймер\ncheck(\n    \"Дисклеймер присутствует\",\n    \"Не является медицинской рекомендацией\" in response,\n)\n\n# 2. Промпт не протёк в ответ\ncheck(\"Нет артефактов промпта (===)\",  \"===\" not in response)\ncheck(\"Нет 'Ваш ответ:'\",              \"Ваш ответ:\" not in response)\ncheck(\"Нет '[system]' / '[user]'\",     \"[system]\" not in response and \"[user]\" not in response)\n\n# 3. Длина ответа\nword_count = len(response.split())\ncheck(\"Длина > 100 слов\",  word_count > 100,  f\"{word_count} слов\")\ncheck(\"Длина < 3000 слов\", word_count < 3000, f\"{word_count} слов\")\n\n# 4. Язык — кириллица присутствует\ncyrillic_ratio = sum(1 for c in response if '\\u0400' <= c <= '\\u04ff') / max(len(response), 1)\ncheck(\"Кириллица в ответе (>30%)\", cyrillic_ratio > 0.3, f\"{cyrillic_ratio:.0%}\")\n\n# 5. Нет явных галлюцинаций-маркеров\nhallucination_markers = [\"по данным ВОЗ\", \"согласно исследованию\", \"в 2023 году\", \"клинические испытания показали\"]\nfound_markers = [m for m in hallucination_markers if m.lower() in response.lower()]\ncheck(\"Нет внешних ссылок-маркеров\", len(found_markers) == 0, \", \".join(found_markers) if found_markers else \"\")\n\nprint(f\"\\nИтого: {sum(1 for s,_,_ in checks if s=='OK  ')}/{len(checks)} OK\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "590d0z9mb9b",
   "source": "### 8.3 Faithfulness — ответ vs retrieved_sections\n\nДля каждого утверждения из ответа проверяем: какой чанк его поддерживает?  \nИспользует эмбеддинг-сходство как прокси — не заменяет экспертную проверку, но сигнализирует о потенциальных галлюцинациях.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "kraag3anq0k",
   "source": "import numpy as np\nimport re\n\nif not retrieved:\n    print(\"retrieved_sections не сохранены в этой версии JSON.\")\n    print(\"Пересобери пайплайн — начиная с v0.3 они сохраняются автоматически.\")\nelse:\n    # Разбиваем ответ на предложения\n    sentences = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', response) if len(s.strip()) > 40]\n\n    # Эмбеддим предложения ответа и retrieved-чанки\n    # embedder должен быть инициализирован в секции 4\n    sent_embs   = embedder.embed_batch(sentences)          # (S, D)\n    chunk_embs  = embedder.embed_batch(retrieved)          # (K, D)\n\n    # Косинусное сходство (векторы уже L2-нормализованы)\n    sim_matrix = sent_embs @ chunk_embs.T                  # (S, K)\n\n    print(f\"Предложений в ответе : {len(sentences)}\")\n    print(f\"Retrieved чанков     : {len(retrieved)}\")\n    print()\n\n    LOW_THRESH = 0.35   # ниже — предложение плохо покрыто чанками\n    flagged = []\n\n    print(f\"{'Сходство':>8}  Предложение\")\n    print(\"-\" * 80)\n    for i, (sent, sims) in enumerate(zip(sentences, sim_matrix)):\n        best_score = float(sims.max())\n        best_chunk = int(sims.argmax())\n        flag = \" ⚠\" if best_score < LOW_THRESH else \"\"\n        if best_score < LOW_THRESH:\n            flagged.append((sent, best_score))\n        print(f\"  {best_score:.3f}{flag}   {sent[:90]}\")\n\n    print()\n    if flagged:\n        print(f\"⚠  {len(flagged)} предложений плохо покрыты retrieved-чанками (score < {LOW_THRESH}):\")\n        for sent, score in flagged:\n            print(f\"   [{score:.3f}] {sent[:120]}\")\n    else:\n        print(\"Все предложения хорошо покрыты retrieved-чанками.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8vpryplt85k",
   "source": "### 8.4 Просмотр retrieved-чанков",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "w7yz7f9gpw",
   "source": "if not retrieved:\n    print(\"retrieved_sections не сохранены в этой версии JSON.\")\nelse:\n    print(f\"Передано в генератор {len(retrieved)} чанков:\\n\")\n    for i, chunk in enumerate(retrieved):\n        print(f\"── Чанк {i} {'─'*60}\")\n        print(chunk)\n        print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ncf56jtf9ej",
   "source": "### 8.5 Сравнение версий",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xnyk78a8kwf",
   "source": "import json\nfrom pathlib import Path\n\nresponse_dir = Path(cfg.response_dir)\nversions = sorted(response_dir.glob(\"version_*.json\"))\n\nif len(versions) < 2:\n    print(\"Нужно минимум 2 версии для сравнения.\")\nelse:\n    rows = []\n    for vf in versions:\n        with vf.open(encoding=\"utf-8\") as f:\n            d = json.load(f)\n        gen_dur   = d.get(\"stage_durations\", {}).get(\"generation\", 0)\n        has_ret   = \"да\" if d.get(\"retrieved_sections\") else \"нет\"\n        has_disc  = \"да\" if \"Не является медицинской рекомендацией\" in d.get(\"final_response\", \"\") else \"НЕТ ⚠\"\n        has_art   = \"ДА ⚠\" if \"Ваш ответ:\" in d.get(\"final_response\", \"\") else \"нет\"\n        wc        = len(d.get(\"final_response\", \"\").split())\n        rows.append((d[\"version\"], d.get(\"mode\",\"—\"), gen_dur, wc, has_disc, has_art, has_ret))\n\n    header = f\"{'ver':>3}  {'mode':<8}  {'gen,s':>7}  {'слов':>5}  {'дисклейм':>9}  {'артефакт':>9}  {'sections':>8}\"\n    print(header)\n    print(\"─\" * len(header))\n    for ver, mode, gen, wc, disc, art, ret in rows:\n        print(f\"  {ver:>2}  {mode:<8}  {gen:>7.1f}  {wc:>5}  {disc:>9}  {art:>9}  {ret:>8}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}